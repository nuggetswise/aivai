# AI-vs-AI Debate Turn Pipeline (LangManus-style)
# This YAML scaffolds the multi-agent flow described in app/readmelangmanus and plan3.
# It is framework-agnostic configuration you can adapt to your runner.

vars:
  freshness_days: 120
  whitelist:
    - europa.eu
    - nist.gov
    - oecd.org
    - who.int
    - reuters.com
    - bbc.com
    - nature.com
    - acm.org
    - mit.edu
    - stanford.edu
  greylist:
    - gov.uk
    - canada.ca
    - company.com/blog
  blacklist:
    - "*-seo-*"
    - "presswire.*"
    - "contentfarm.*"

agents:
  researcher:
    description: "Gathers factual evidence from web + local corpus for the debate turn"
    model: basic-llm
    tools:
      - name: tavily_search
        args:
          num_results: 12
          freshness_days: "{{ freshness_days }}"
          whitelist: "{{ whitelist }}"
          greylist: "{{ greylist }}"
          blacklist: "{{ blacklist }}"
      - name: web.fetch
      - name: html.clean_readability
    input_schema:
      type: object
      properties:
        topic: { type: string }
        intent: { type: string }
        opponent_point: { type: string }
        local_corpus: { type: array, items: { type: string } }
    output_schema:
      type: object
      properties:
        claims:
          type: array
          items:
            type: object
            properties:
              text: { type: string }
              citations: { type: array, items: { type: string } }
              confidence: { type: number }
        contradictions: { type: array }
        omissions: { type: array }
    system_prompt_file: "app/prompts/researcher.txt"

  commentator:
    description: "Generates persona-locked debate turn from evidence bundle"
    model: reasoning-llm
    temperature: 0.25
    input_schema:
      type: object
      properties:
        topic: { type: string }
        phase: { type: string }
        intent: { type: string }
        opponent_summary: { type: string }
        persona: { type: object }
        evidence_bundle: { type: object }
    output_schema:
      type: object
      properties:
        text: { type: string }
        citations: { type: array, items: { type: string } }
    system_prompt_file: "app/prompts/commentator.txt"

  verifier:
    description: "Checks factual support for each sentence and fixes or removes unsupported claims"
    model: basic-llm
    temperature: 0
    input_schema:
      type: object
      properties:
        draft: { type: string }
        evidence_bundle: { type: object }
        persona: { type: object }
    output_schema:
      type: object
      properties:
        text: { type: string }
        citations: { type: array, items: { type: string } }
    system_prompt: |
      Validate factual support for each sentence in the draft.
      If a sentence has wrong or missing citation, minimally edit to match the evidence or replace with "{{ persona.default_unknown }}".
      Do not add new facts.

  style:
    description: "Adjusts tone and style to match persona without altering facts or citations"
    model: basic-llm
    temperature: 0
    input_schema:
      type: object
      properties:
        verified_text: { type: string }
        persona: { type: string }
    output_schema:
      type: object
      properties:
        styled_text: { type: string }
    system_prompt_file: "app/prompts/style.txt"

  tts:
    description: "Synthesizes audio for the final styled text using configured TTS adapter"
    model: local
    run: python app/tts/adapter.py --text "{{ styled_text }}" --persona "{{ persona }}"
    input_schema:
      type: object
      properties:
        styled_text: { type: string }
        persona: { type: object }
    output_schema:
      type: object
      properties:
        audio_path: { type: string }

pipelines:
  debate_turn:
    steps:
      - agent: researcher
      - agent: commentator
      - agent: verifier
      - agent: style
      - agent: tts
